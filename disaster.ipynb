{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "disaster.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM5sDBmDLaxuDCTL7t5uAMM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gail529/Text-Classification-/blob/master/disaster.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMKiGOthUtfb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2be3b673-bd5e-4fd8-b6ef-1e33383fd833"
      },
      "source": [
        "#importing the relevant libraries and packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import re \n",
        "import string\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXNSaBvWWCCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('/content/train.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS6POage8-il",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "265b84ec-74df-4f0e-fbd8-a2b01b42f9cd"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NMEKcKgYrOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preprocessing all the songs\n",
        "for i in range(0,len(data)):\n",
        "    tweet=data.iloc[i,3]\n",
        "    #removing numbers\n",
        "    text=re.sub(r'\\d+','',tweet)\n",
        " \n",
        "    #lowercasing\n",
        "    text_lower=text.lower()\n",
        " \n",
        "    #punctuation removal \n",
        "    def  remove_punctuation(word): #function will take in the lowercased text and then remove all the punctuation\n",
        "        translator=str.maketrans('','',string.punctuation)\n",
        "        text_punct=word.translate(translator)\n",
        "        return text_punct\n",
        "    result=remove_punctuation(text_lower) #storing the resulting body of  text in variable result\n",
        " \n",
        "    #removing stopwords \n",
        "    def remove_stopwords(word):#The function will tokenize the result and then filter off  the stop_words \n",
        "        stop_words=set(stopwords.words(\"english\")) \n",
        "        word_tokens= word_tokenize(word)\n",
        "        result=[word for word in word_tokens if word not in stop_words] \n",
        "        return result\n",
        "    preprocessed_tweet=remove_stopwords(result)\n",
        " \n",
        "    #replacing the values of the lyrics column in the dataframe with the  preprocessed  lyrics\n",
        "    data.iat[i,3]=preprocessed_tweet"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoC27ED7nlki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "42408709-c478-47ca-a143-b21f4a6399fc"
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[deeds, reason, earthquake, may, allah, forgiv...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[people, receive, wildfires, evacuation, order...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  [deeds, reason, earthquake, may, allah, forgiv...      1\n",
              "1   4     NaN  ...      [forest, fire, near, la, ronge, sask, canada]      1\n",
              "2   5     NaN  ...  [residents, asked, shelter, place, notified, o...      1\n",
              "3   6     NaN  ...  [people, receive, wildfires, evacuation, order...      1\n",
              "4   7     NaN  ...  [got, sent, photo, ruby, alaska, smoke, wildfi...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjKCPxn1PohJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence =nltk.sent_tokenize(text)\n",
        "word=[nltk.word_tokenize(sentence) for sentence in sentences]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTKE1Ih0Q8Cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Word2Vec(sentences,min_count=1)\n",
        "words=model.wv.vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKeKrXBXGSgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "2687aef1-4d7a-4344-9205-ba927949fe54"
      },
      "source": [
        "sample=data.tail(20)\n",
        "sample"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7593</th>\n",
              "      <td>10848</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[heard, really, loud, bang, everyone, asleep, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7594</th>\n",
              "      <td>10849</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[gas, thing, exploded, heard, screams, whole, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7595</th>\n",
              "      <td>10850</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[nws, flash, flood, warning, continued, shelby...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7596</th>\n",
              "      <td>10851</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[rt, livingsafely, nws, issues, severe, thunde...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7597</th>\n",
              "      <td>10852</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[mh, aircraft, debris, found, la, reunion, mis...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7598</th>\n",
              "      <td>10853</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[fatherofthree, lost, control, car, overtaking...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7599</th>\n",
              "      <td>10854</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[earthquake, km, ssw, anza, california, iphone...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7600</th>\n",
              "      <td>10855</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[evacuation, order, lifted, town, roosevelt, h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7601</th>\n",
              "      <td>10859</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[breaking, la, refugio, oil, spill, may, costl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7602</th>\n",
              "      <td>10860</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[siren, went, wasnt, forney, tornado, warning]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7603</th>\n",
              "      <td>10862</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[officials, say, quarantine, place, alabama, h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7604</th>\n",
              "      <td>10863</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[worldnews, fallen, powerlines, glink, tram, u...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7605</th>\n",
              "      <td>10864</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[flip, side, im, walmart, bomb, everyone, evac...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7606</th>\n",
              "      <td>10866</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[suicide, bomber, kills, saudi, security, site...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7607</th>\n",
              "      <td>10867</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[stormchase, violent, record, breaking, ef, el...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>10869</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[two, giant, cranes, holding, bridge, collapse...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>10870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[ariaahrary, thetawniest, control, wild, fires...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>10871</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[utckm, volcano, hawaii, httptcozdtoydebj]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>10872</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[police, investigating, ebike, collided, car, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>10873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[latest, homes, razed, northern, california, w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id keyword  ...                                               text target\n",
              "7593  10848     NaN  ...  [heard, really, loud, bang, everyone, asleep, ...      0\n",
              "7594  10849     NaN  ...  [gas, thing, exploded, heard, screams, whole, ...      1\n",
              "7595  10850     NaN  ...  [nws, flash, flood, warning, continued, shelby...      1\n",
              "7596  10851     NaN  ...  [rt, livingsafely, nws, issues, severe, thunde...      1\n",
              "7597  10852     NaN  ...  [mh, aircraft, debris, found, la, reunion, mis...      1\n",
              "7598  10853     NaN  ...  [fatherofthree, lost, control, car, overtaking...      1\n",
              "7599  10854     NaN  ...  [earthquake, km, ssw, anza, california, iphone...      1\n",
              "7600  10855     NaN  ...  [evacuation, order, lifted, town, roosevelt, h...      1\n",
              "7601  10859     NaN  ...  [breaking, la, refugio, oil, spill, may, costl...      1\n",
              "7602  10860     NaN  ...     [siren, went, wasnt, forney, tornado, warning]      1\n",
              "7603  10862     NaN  ...  [officials, say, quarantine, place, alabama, h...      1\n",
              "7604  10863     NaN  ...  [worldnews, fallen, powerlines, glink, tram, u...      1\n",
              "7605  10864     NaN  ...  [flip, side, im, walmart, bomb, everyone, evac...      1\n",
              "7606  10866     NaN  ...  [suicide, bomber, kills, saudi, security, site...      1\n",
              "7607  10867     NaN  ...  [stormchase, violent, record, breaking, ef, el...      1\n",
              "7608  10869     NaN  ...  [two, giant, cranes, holding, bridge, collapse...      1\n",
              "7609  10870     NaN  ...  [ariaahrary, thetawniest, control, wild, fires...      1\n",
              "7610  10871     NaN  ...         [utckm, volcano, hawaii, httptcozdtoydebj]      1\n",
              "7611  10872     NaN  ...  [police, investigating, ebike, collided, car, ...      1\n",
              "7612  10873     NaN  ...  [latest, homes, razed, northern, california, w...      1\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uah4PnA3rsRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=data['target']\n",
        "x=data['text']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPzhNJM_-O9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_7X7A8KRi5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vectorization using Bag of Words\n",
        "cv=CountVectorizer(tokenizer=lambda doc:doc,lowercase=False,max_features=1500)\n",
        "x_bow=cv.fit_transform(x_train).toarray()\n",
        "x_bow_test=cv.fit_transform(x_test).toarray()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlBC6ikVrC6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f703576e-eeac-4e89-ba7c-7970a5757046"
      },
      "source": [
        "x_bow.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5329, 1500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3yI4ECDy7bg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "574243d1-9290-4418-c74c-3461c121a2a2"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5329,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDYjYIw7-_Q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        " \n",
        "#text Vectorization using TFIDF\n",
        "def dummy_fun(doc):\n",
        "    return doc\n",
        " \n",
        "#vectorizing the text\n",
        "tfidf=TfidfVectorizer(\n",
        "    analyzer='word',\n",
        "    tokenizer=dummy_fun,\n",
        "    preprocessor=dummy_fun,\n",
        "    token_pattern=None)\n",
        "tfidf.fit(x)\n",
        "x_tfidf=tfidf.transform(x_train)\n",
        "x_tfidf_test=tfidf.transform(x_test)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP9phjhzbnMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ec64bbf2-2c84-43d7-be91-8c889a40259d"
      },
      "source": [
        "#training the SVM model\n",
        "#using BOW\n",
        "from sklearn import model_selection,svm\n",
        "SVM=svm.SVC(C=1.0,kernel='linear')\n",
        "SVM.fit(x_bow,y_train)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1t9wWK24xpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svm_predictions=SVM.predict(x_bow_test)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3YlSQv0Bnb4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "1ef82fde-571b-4d61-d94d-c3baed1c2803"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,svm_predictions))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.63      0.59      1280\n",
            "           1       0.44      0.38      0.41      1004\n",
            "\n",
            "    accuracy                           0.52      2284\n",
            "   macro avg       0.50      0.50      0.50      2284\n",
            "weighted avg       0.51      0.52      0.51      2284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPq27rczAeDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#text Vectorization using TFIDF\n",
        "def dummy_fun(doc):\n",
        "    return doc\n",
        " \n",
        "#vectorizing the text\n",
        "tfidf=TfidfVectorizer(\n",
        "    analyzer='word',\n",
        "    tokenizer=dummy_fun,\n",
        "    preprocessor=dummy_fun,\n",
        "    token_pattern=None)\n",
        "tfidf.fit(x)\n",
        "x_tfidf=tfidf.transform(x_train)\n",
        "x_tfidf_test=tfidf.transform(x_test)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU6kfFX460sx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "85f8a816-4d34-45de-802f-c988bb485def"
      },
      "source": [
        "#training the SVM model\n",
        "#tfidf word vector\n",
        "from sklearn import model_selection,svm\n",
        "SVM=svm.SVC(C=1.0,kernel='linear')\n",
        "SVM.fit(x_tfidf,y_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmcy3x-M_ICU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=SVM.predict(x_tfidf_test)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4CI05e2_gZZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "79ca0fde-a85f-483a-a695-f0bd7f9f0741"
      },
      "source": [
        "from sklearn.metrics import classification_report  #training the model using tfidf provides a higher accuracy for SVM\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.89      0.83      1280\n",
            "           1       0.83      0.67      0.74      1004\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.78      0.79      2284\n",
            "weighted avg       0.80      0.80      0.79      2284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD8n47tcllK_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69e5b4fc-ad89-4151-83b3-1b0eaa1392f6"
      },
      "source": [
        "#using naive bayes with BOW word vector\n",
        "from sklearn import model_selection,naive_bayes\n",
        "nb=naive_bayes.MultinomialNB()\n",
        "nb.fit(x_bow,y_train)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekc_ZLe08Zg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_Predictions=nb.predict(x_bow_test)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCIELF7ADRw9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "bd3d4b7f-955b-46ff-d976-cc01689e5552"
      },
      "source": [
        "print(classification_report(y_test,nb_Predictions))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.57      0.57      1280\n",
            "           1       0.46      0.46      0.46      1004\n",
            "\n",
            "    accuracy                           0.52      2284\n",
            "   macro avg       0.51      0.51      0.51      2284\n",
            "weighted avg       0.52      0.52      0.52      2284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8ZPRdCMC2GZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03b5fde0-b001-4366-d223-c51a89eef8dd"
      },
      "source": [
        "#using naive bayes with BOW word vector\n",
        "from sklearn import model_selection,naive_bayes\n",
        "nb=naive_bayes.MultinomialNB()\n",
        "nb.fit(x_tfidf,y_train)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG_AMTE2DHCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "428c946e-f415-4c5f-c985-dd7432d41cc1"
      },
      "source": [
        "nb_tfidf_Predictions=nb.predict(x_tfidf_test)               #using tfidf provides a higher accuracy than BOW for the\n",
        "print(classification_report(y_test,nb_tfidf_Predictions))     #Naive bayes classifier\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.92      0.83      1280\n",
            "           1       0.86      0.64      0.73      1004\n",
            "\n",
            "    accuracy                           0.79      2284\n",
            "   macro avg       0.81      0.78      0.78      2284\n",
            "weighted avg       0.81      0.79      0.79      2284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND90x93mElGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using Gridsearchcv\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {'C':[0.1,1,10],'gamma':[1,0.1,0.01],'kernel':['linear']}"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y_78QUu6ViV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD5yu-pYK9nG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02f3ef15-873b-4601-e5dc-41f20438d1de"
      },
      "source": [
        "print(grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': 1, 'gamma': 1, 'kernel': 'linear'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyAuPWtgLGkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e783ba92-5ff6-473a-c6f3-98532f3947ea"
      },
      "source": [
        "print(grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=1, kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hdMh6tZLL2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_predictions=grid.predict(x_test_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBQWbAZgLYM3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "58db7015-f4a8-4b59-de5f-bdab937c9e00"
      },
      "source": [
        "print(classification_report(y_test,g_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.89      0.83      1312\n",
            "           1       0.82      0.67      0.73       972\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.78      0.78      2284\n",
            "weighted avg       0.80      0.80      0.79      2284\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}